{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditiwu/AriesCurrencyProject/blob/master/Countries_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "31TA5tPxHKiP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY_Iv4ZulikR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score as r2\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "from keras.layers.core import Dense\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "import random\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from collections import Counter \n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pathlib\n",
        "gen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.15, zoom_range=0.1, \n",
        "    channel_shift_range=10., horizontal_flip=True)"
      ],
      "metadata": {
        "id": "X_T6i3-yAzhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKyRZ9Smn-tk",
        "outputId": "35e1037a-1247-43ed-9aec-0e2dc7461b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1E3-7WQmkDJ"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH=200\n",
        "IMG_HEIGHT=200"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = []\n",
        "image_path= r'//content//drive//MyDrive//Aries Dataset//USD//1//Image_1.png'                \n",
        "image= cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "image=np.array(image)\n",
        "image = image.astype('float32')\n",
        "image /= 255\n",
        "x.append(image)\n"
      ],
      "metadata": {
        "id": "oFW0SmWv3be_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = r'//content//drive//MyDrive//Aries Dataset'\n",
        "d={}\n",
        "for file in os.listdir(path):\n",
        "  for file1 in os.listdir(os.path.join(path, file)):\n",
        "    for file2 in os.listdir(os.path.join(path, file, file1)):\n",
        "      try:\n",
        "        d[file]+=1\n",
        "      except:\n",
        "        d[file]=1\n",
        "path = r'//content//drive//MyDrive//Aries Bad'\n",
        "for file in os.listdir(path):\n",
        "  for file1 in os.listdir(os.path.join(path, file)):\n",
        "    for file2 in os.listdir(os.path.join(path, file, file1)):\n",
        "      try:\n",
        "        d[file]+=1\n",
        "      except:\n",
        "        d[file]=1"
      ],
      "metadata": {
        "id": "HP3heye7-azU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for keys,values in d.items(): \n",
        "\n",
        "  print(keys) \n",
        "\n",
        "  print(values)\n",
        "\n",
        "  print(' ')"
      ],
      "metadata": {
        "id": "hKhfiHl--daF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19957cb2-87f5-42cc-f956-9e55c7e0a3b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USD\n",
            "907\n",
            " \n",
            "Euro\n",
            "503\n",
            " \n",
            "Australian dollar\n",
            "554\n",
            " \n",
            "Malaysian ringgit\n",
            "717\n",
            " \n",
            "Polish z≈Çoty\n",
            "472\n",
            " \n",
            "singapore dollar\n",
            "850\n",
            " \n",
            "thai baht\n",
            "546\n",
            " \n",
            "turkish lira\n",
            "611\n",
            " \n",
            "YEN\n",
            "611\n",
            " \n",
            "NZD\n",
            "521\n",
            " \n",
            "SEK\n",
            "613\n",
            " \n",
            "SKW\n",
            "587\n",
            " \n",
            "Hong Kong dollar-sorted\n",
            "752\n",
            " \n",
            "Philippine peso-sorted\n",
            "700\n",
            " \n",
            "Pound Sterling-sorted\n",
            "484\n",
            " \n",
            "Russian Ruble-sorted\n",
            "766\n",
            " \n",
            "Indian Currencies\n",
            "1130\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QT4u9fJDHmr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Nsj-MkHmtRN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54c6731c-efb1-41f7-e3c8-731a47b3304a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "//content//drive//MyDrive//Aries Dataset/Australian dollar/10/Image_117.png\n",
            "//content//drive//MyDrive//Aries Dataset/Australian dollar/100/Image_179.png\n",
            "//content//drive//MyDrive//Aries Dataset/Malaysian ringgit/5/Image_68.png\n",
            "//content//drive//MyDrive//Aries Dataset/turkish lira/20/Image_131.jpeg\n",
            "//content//drive//MyDrive//Aries Dataset/turkish lira/20/Image_137.jpeg\n",
            "//content//drive//MyDrive//Aries Dataset/NZD/100/Image_64.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "//content//drive//MyDrive//Aries Dataset/Philippine peso-sorted/500/Image_92.gif\n",
            "//content//drive//MyDrive//Aries Dataset/Philippine peso-sorted/100/Image_97.png\n"
          ]
        }
      ],
      "source": [
        "def create_dataset(img_folder, im_folder1):\n",
        "   \n",
        "    img_data_array=[]\n",
        "    class_name=[]\n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for dir2 in os.listdir(os.path.join(img_folder, dir1)):\n",
        "            for file in os.listdir(os.path.join(img_folder, dir1, dir2)):\n",
        "                if(dir1==\"USD\" or dir1==\"singapore dollar\"):\n",
        "                    image_path= os.path.join(img_folder, dir1, dir2,  file)\n",
        "                    image= cv2.imread(image_path)\n",
        "                    try:\n",
        "                      image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "                      image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "                      image=np.array(image)\n",
        "                      image = image.astype('float32')\n",
        "                      image /= 255\n",
        "                      img_data_array.append(image)\n",
        "                      x[-1]=image\n",
        "                      class_name.append(dir1)\n",
        "                    except:\n",
        "                      print(image_path)\n",
        "                else:\n",
        "                    image_path= os.path.join(img_folder, dir1, dir2,  file)\n",
        "                    image= cv2.imread(image_path)\n",
        "                    try:\n",
        "                        imgp = np.expand_dims(plt.imread(image_path),0)\n",
        "                        aug_iter = gen.flow(imgp)\n",
        "                        aug_images = [next(aug_iter)[0].astype(np.float32) for i in range(1)]\n",
        "                        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "                        image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "                        image=np.array(image)\n",
        "                        image = image.astype('float32')\n",
        "                        image /= 255\n",
        "                        img_data_array.append(image)\n",
        "                        class_name.append(dir1)\n",
        "                        for i in range(1):\n",
        "                            img = aug_images[i]\n",
        "                            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "                            image=np.array(image)\n",
        "                            image = image.astype('float32')\n",
        "                            image /= 255\n",
        "                            img_data_array.append(image)\n",
        "                            class_name.append(dir1)\n",
        "                    except:\n",
        "                          print(image_path)\n",
        "    for dir1 in os.listdir(im_folder1):\n",
        "        for dir2 in os.listdir(os.path.join(im_folder1, dir1)):\n",
        "            for file in os.listdir(os.path.join(im_folder1, dir1, dir2)):\n",
        "                image_path= os.path.join(im_folder1, dir1, dir2,  file)\n",
        "                \n",
        "                image= cv2.imread(image_path)\n",
        "                try:\n",
        "                  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "                  image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "                  image=np.array(image)\n",
        "                  image = image.astype('float32')\n",
        "                  image /= 255\n",
        "                  img_data_array.append(image)\n",
        "                  x[-1]=image\n",
        "                  class_name.append(dir1)\n",
        "                except:\n",
        "                  print(image_path)                \n",
        "                \n",
        "    return img_data_array, class_name\n",
        "# extract the image array and class name\n",
        "img_data, class_name =create_dataset(r'//content//drive//MyDrive//Aries Dataset',r'//content//drive//MyDrive//Aries Bad')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LEhSTUtmvdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c706450-4943-4201-c8ff-7657bb0dfa29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Australian dollar': 0, 'Euro': 1, 'Hong Kong dollar-sorted': 2, 'Indian Currencies': 3, 'Malaysian ringgit': 4, 'NZD': 5, 'Philippine peso-sorted': 6, 'Polish z≈Çoty': 7, 'Pound Sterling-sorted': 8, 'Russian Ruble-sorted': 9, 'SEK': 10, 'SKW': 11, 'USD': 12, 'YEN': 13, 'singapore dollar': 14, 'thai baht': 15, 'turkish lira': 16}\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(img_data,\n",
        "                                                    class_name,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "target_dict={k: v for v, k in enumerate(np.unique(y_train))}\n",
        "target_val=  [target_dict[y_train[i]] for i in range(len(y_train))]\n",
        "target_dict1={k: v for v, k in enumerate(np.unique(y_test))}\n",
        "target_val1=  [target_dict[y_test[i]] for i in range(len(y_test))]\n",
        "print(target_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(target_dict)\n",
        "print(target_dict1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSZMjsgiEVNO",
        "outputId": "1e3e2887-58ae-411e-fa79-1b1b55fad3da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Australian dollar': 0, 'Euro': 1, 'Hong Kong dollar-sorted': 2, 'Indian Currencies': 3, 'Malaysian ringgit': 4, 'NZD': 5, 'Philippine peso-sorted': 6, 'Polish z≈Çoty': 7, 'Pound Sterling-sorted': 8, 'Russian Ruble-sorted': 9, 'SEK': 10, 'SKW': 11, 'USD': 12, 'YEN': 13, 'singapore dollar': 14, 'thai baht': 15, 'turkish lira': 16}\n",
            "{'Australian dollar': 0, 'Euro': 1, 'Hong Kong dollar-sorted': 2, 'Indian Currencies': 3, 'Malaysian ringgit': 4, 'NZD': 5, 'Philippine peso-sorted': 6, 'Polish z≈Çoty': 7, 'Pound Sterling-sorted': 8, 'Russian Ruble-sorted': 9, 'SEK': 10, 'SKW': 11, 'USD': 12, 'YEN': 13, 'singapore dollar': 14, 'thai baht': 15, 'turkish lira': 16}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "counter=Counter(target_val)\n",
        "print(counter)"
      ],
      "metadata": {
        "id": "wpYZ4-xAmn2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e7df68b-e61c-4de2-af79-d1ee4c62003c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({9: 1102, 2: 1038, 4: 991, 6: 970, 10: 874, 13: 841, 11: 833, 16: 819, 3: 794, 15: 770, 0: 758, 5: 725, 1: 712, 8: 680, 12: 661, 7: 661, 14: 592})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                 input_shape=(IMG_HEIGHT, \n",
        "                                                              IMG_WIDTH,\n",
        "                                                              1)),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "1e8SpVe8oQeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install livelossplot==0.1.2"
      ],
      "metadata": {
        "id": "lTJF5vC-C02s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a691e6-c4f4-43d4-c400-bfc4214af298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting livelossplot==0.1.2\n",
            "  Downloading livelossplot-0.1.2.tar.gz (3.9 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot==0.1.2) (3.2.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from livelossplot==0.1.2) (5.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot==0.1.2) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot==0.1.2) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot==0.1.2) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot==0.1.2) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot==0.1.2) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->livelossplot==0.1.2) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->livelossplot==0.1.2) (1.15.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.1.2) (4.10.1)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.1.2) (5.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.1.2) (2.11.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.1.2) (0.2.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.1.2) (5.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.1.2) (5.1.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.1.2) (0.13.3)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.1.2) (5.3.5)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.1.2) (5.4.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.1.2) (1.8.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.1.2) (4.10.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook->livelossplot==0.1.2) (23.1.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->livelossplot==0.1.2) (0.7.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->notebook->livelossplot==0.1.2) (5.5.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.1.2) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.1.2) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.1.2) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.1.2) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.1.2) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.1.2) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.1.2) (2.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook->livelossplot==0.1.2) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->livelossplot==0.1.2) (2.0.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->livelossplot==0.1.2) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->livelossplot==0.1.2) (0.6.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->livelossplot==0.1.2) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->livelossplot==0.1.2) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->livelossplot==0.1.2) (0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->livelossplot==0.1.2) (5.0.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->livelossplot==0.1.2) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->livelossplot==0.1.2) (2.15.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->livelossplot==0.1.2) (4.11.4)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->livelossplot==0.1.2) (21.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->livelossplot==0.1.2) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->livelossplot==0.1.2) (5.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook->livelossplot==0.1.2) (3.8.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook->livelossplot==0.1.2) (0.5.1)\n",
            "Building wheels for collected packages: livelossplot\n",
            "  Building wheel for livelossplot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for livelossplot: filename=livelossplot-0.1.2-py3-none-any.whl size=3828 sha256=e32e1d17531a1497ba64e17dfbfa6e995ff68214de4ec90d151737e0c7f80fdc\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/78/c7/7d1e3952810ddf926b4d4dbf536a52e7b6821bd54b6f6a84a8\n",
            "Successfully built livelossplot\n",
            "Installing collected packages: livelossplot\n",
            "Successfully installed livelossplot-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from livelossplot import PlotLossesKeras"
      ],
      "metadata": {
        "id": "KwLPCRTPCn-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B45BQGZLyEYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6869aee-0f76-4da7-aaaa-2f1343d1d88d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000000\n",
            "432/432 [==============================] - 26s 25ms/step - loss: 2.5750 - accuracy: 0.1848\n",
            "Epoch 2/10000000\n",
            "432/432 [==============================] - 10s 24ms/step - loss: 1.9543 - accuracy: 0.4099\n",
            "Epoch 3/10000000\n",
            "432/432 [==============================] - 10s 24ms/step - loss: 1.6154 - accuracy: 0.4970\n",
            "Epoch 4/10000000\n",
            "432/432 [==============================] - 10s 24ms/step - loss: 1.4067 - accuracy: 0.5502\n",
            "Epoch 5/10000000\n",
            "432/432 [==============================] - 10s 24ms/step - loss: 1.2718 - accuracy: 0.5895\n",
            "Epoch 6/10000000\n",
            "432/432 [==============================] - 11s 24ms/step - loss: 1.2046 - accuracy: 0.6015\n",
            "Epoch 7/10000000\n",
            "432/432 [==============================] - 11s 24ms/step - loss: 1.1711 - accuracy: 0.6050\n",
            "Epoch 8/10000000\n",
            "432/432 [==============================] - 11s 25ms/step - loss: 1.1559 - accuracy: 0.6070\n",
            "Epoch 9/10000000\n",
            "432/432 [==============================] - 11s 24ms/step - loss: 1.1476 - accuracy: 0.6059\n",
            "Epoch 10/10000000\n",
            "432/432 [==============================] - 11s 25ms/step - loss: 1.1432 - accuracy: 0.6103\n",
            "Epoch 11/10000000\n",
            "432/432 [==============================] - 11s 25ms/step - loss: 1.1405 - accuracy: 0.6070\n",
            "Epoch 12/10000000\n",
            "432/432 [==============================] - 11s 25ms/step - loss: 1.1376 - accuracy: 0.6063\n",
            "Epoch 13/10000000\n",
            "432/432 [==============================] - 11s 25ms/step - loss: 1.1361 - accuracy: 0.6073\n",
            "Epoch 14/10000000\n",
            "432/432 [==============================] - 11s 24ms/step - loss: 1.1349 - accuracy: 0.6102\n",
            "Epoch 15/10000000\n",
            "432/432 [==============================] - 11s 24ms/step - loss: 1.1335 - accuracy: 0.6091\n",
            "Epoch 16/10000000\n",
            "432/432 [==============================] - 11s 25ms/step - loss: 1.1566 - accuracy: 0.6048\n",
            "Epoch 17/10000000\n",
            "432/432 [==============================] - 11s 24ms/step - loss: 1.1539 - accuracy: 0.6051\n",
            "Epoch 18/10000000\n",
            "432/432 [==============================] - 11s 24ms/step - loss: 1.1345 - accuracy: 0.6099\n"
          ]
        }
      ],
      "source": [
        "model = models.Sequential()\n",
        "#model.add(data_augmentation)\n",
        "model.add(layers.Conv2D(16, (3, 3) , activation='relu', input_shape=(200, 200, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "#model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='sigmoid'))\n",
        "model.add(layers.Dense(17))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "history = model.fit(x=np.array(X_train, np.float32), y=np.array(list(map(int,target_val)), np.float32), epochs=10000000, callbacks=[callback])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "V-3CigsQAwbJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fda67a60-a1ae-4449-b6a1-ff59b0155be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 198, 198, 16)      160       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 99, 99, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 97, 97, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 48, 48, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 46, 46, 64)        18496     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 135424)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8667200   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 17)                1105      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,691,601\n",
            "Trainable params: 8,691,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "xznlFQRKHO5E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vd17iZPzyLEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d37164ec-9f01-498d-ce71-6553b733cc8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186/186 [==============================] - 2s 11ms/step - loss: 1.6315 - accuracy: 0.4912\n",
            "\n",
            "Test accuracy: 0.4912221431732178\n",
            "INFO:tensorflow:Assets written to: //content//drive//MyDrive//Countries_sample_save/assets\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(np.array(X_test, np.float32), np.array(list(map(int,target_val1))))\n",
        "print('\\nTest accuracy: {}'.format(test_acc))\n",
        "model.save(r'//content//drive//MyDrive//Countries_sample_save')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Countries_sample.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xznlFQRKHO5E"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}